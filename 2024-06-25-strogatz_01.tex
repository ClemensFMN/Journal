\DiaryEntry{Strogatz, I}{2024-06-25}{ODE}

\subsection{Introduction - first-order ODEs}

Consider the simple homogeneous differential equation,

\begin{equation}\label{2024-06-25:eq1}
y'(t) + p(t) y(t) = 0
\end{equation}

We can use separation of variables to solve as follows,

\bee
\frac{dy(t)}{dt} + p(t) y(t) = 0 \rightarrow \frac{dy(t)}{y(t)} = - p(t) y(t)
\eee

Integrating both sides yields

\bee
\ln y(t) = -P(t) + C \rightarrow y(t) = D e^{-P(t)}
\eee

where we have defined 

\bee
P(t) = \int p(t) dt
\eee

If we find a closed-form expression to the differential equation depends on the integratability of $p(t)$.

Now let's consider the inhomogeneous counterpart,

\begin{equation}\label{2024-06-25:eq2}
y'(t) + p(t) y(t) = f(t)
\end{equation}

The solution $y(t)$ can be shown to consist of two parts,

\bee
y(t) = g(t) + h(t)
\eee

where $g(t)$ solves the homogeneous differential equation \eqref{2024-06-25:eq1} and $h(t)$ is a \emph{particular} solution. This particular solution can be found via several methods; in the following we consider the \emph{variation of parameters} approach. We set

\bee
h(t) = v(t) g(t)
\eee

and inserting this into \eqref{2024-06-25:eq2} yields

\begin{align*}
h'(t) + p(t) h(t) &= \left( v(t)g(t)\right)' + p(t) v(t) g(t) = v'(t) g(t) + v(t) g'(t) + p(t) v(t) g(t) \\
                  &= v(t) \left[ g'(t) + p(t) g(t) \right] + v'(t) g(t) = v'(t) g(t)
\end{align*}

where we have used the fact that $g'(t) + p(t) g(t) = 0$ because $g(t)$ is the solution to the homogeneous differential equation.

So from this we take that $v'(t) g(t) = f(t)$ for $h(t)$ to be a particular solution. From this we obtain

\bee
v'(t) = \frac{f(t)}{g(t)}
\eee

and the solution to \eqref{2024-06-25:eq2} becomes

\bee
y(t) = v(t) e^{-P(t)} + A e^{-P(t)}
\eee

\subsection{Introduction - Linear ODE systems}

\be\label{2024-06-25:eq3}
\ybf' = \Abf \ybf
\ee

As a side note, the system has one fixed point at $\zerobf$.

We assume the matrix $\Abf$ has eigenvalues $\lambda_1, \lambda_2, \ldots, \lambda_N$ and corresponding eigenvectors $\ubf_1, \ubf_2, \ldots, \ubf_N$. We collect the eigenvectors column-wise into a matrix $\Ubf$ and the eigenvalues in a diagonal matrix $\Lbf$.

This allows us to factor the matrix (eigenvalue decomposition) as

\bee
\Abf = \Ubf \Lbf \Ubf^{-1}
\eee

The solutions $\ybf(t)$ to the ODE system \eqref{2024-06-25:eq3} are then 

\bee
\ybf(t) = c_1 \ubf_1 e^{\lambda_1 t)} + \cdots + c_N \ubf_N e^{\lambda_N t)}
\eee

where the constants $c_i$ depend on the initial conditions. So we have a linear combination of exponentials (whose decay is determined by the $\lambda_i$s) in the direction of the eigenvectors $\ubf_i$.

We next consider the $2-$dimensional case where the following cases exist: (i) Two real distinct eigenvalues, (ii) complex eigenvalues, (iii) repeated (real) eigenvalues.

\paragraph{Two real distinct eigenvalues.} Here we can subdivide into three cases: Both eigenvalues negative $\lambda_2 < \lambda_1 < 0$, both eigenvalues positive $0 < \lambda_2 < \lambda_1$, and one negative, one positive $\lambda_2 < 0 < \lambda_1$.

When both are positive, the exponentials are diverging as $t \rightarrow \infty$ and the fixed point is a source. If the matrix $\Abf$ is not "special", the eigenvectors are linearly independent, but not orthogonal; so in most cases we see a linear combination of both solutions,

\bee
\ybf(t) = c_1 \ubf_1 e^{\lambda_1 t)} + c_2 \ubf_2 e^{\lambda_2 t)}
\eee

If the eigenvectors are orthogonal (for example, in case of diagonal matrices), then we have

\bee
\ybf(t) = c_1 \begin{pmatrix} 1 \\ 0 \end{pmatrix} e^{\lambda_1 t)} + c_2 \begin{pmatrix} 0 \\ 1 \end{pmatrix} e^{\lambda_2 t)}
\eee

and we can see the effect of the different eigenvalues in the components of $\ybf(t)$.

When both eigenvalues are negative, then the exponentials are converging as $t \rightarrow \infty$ and the fixed point is a sink.

More interesting is the case where the two eigenvalues have different sign, $\lambda_2 < 0 < \lambda_1$. Here we have a saddle point, where one solution represents a sink ($\lambda_1 > 0$), the other a source ($\lambda_2 < 0$).

\paragraph{Complex Eigenvalues.}

Here we get complex solutions, which we can rewrite as (increasing / decreasing) oscillations,

\bee
\ybf(t) = c_1 \begin{pmatrix} \cos \beta t \\ - \sin \beta t \end{pmatrix} e^{\alpha t)} + c_2 \begin{pmatrix} \sin \beta t \\ \cos \beta t \end{pmatrix} e^{\alpha t)}
\eee

\paragraph{Repeated Eigenvalues}

In case of a (scaled) identity matrix $\Abf$, we have one eigenvalue $\lambda$, but still two eigenvectors. The solution is then 

\bee
\ybf(t) = c_1 \begin{pmatrix} 1 \\ 0 \end{pmatrix} e^{\lambda t)} + c_2 \begin{pmatrix} 0 \\ 1 \end{pmatrix} e^{\lambda t)}
\eee

In case of a system

\bee
\Abf = \begin{pmatrix} \lambda & b \\ 0 & \lambda \end{pmatrix}
\eee

we have one eigenvalue and one eigenvector and this is covered in the next Subsection.

\subsection{Exercise 5.2.11}

Here we are given a system of linear differential equations determined by the matrix $\Abf$,

\bee
\Abf = \begin{pmatrix} \lambda & b \\ 0 & \lambda \end{pmatrix}
\eee

We can show that this matrix has one eigenvalue equal $\lambda$ and the corresponding eigenvector is $(1,0)^T$.

This corresponds to the following system

\begin{align*}
x'(t) &= \lambda x(t) + b y(t) \\
y'(t) &= \lambda y(t)
\end{align*}

Note that the two differential equations are "asymmetrically" coupled; the second one affects the first, but ot the other way round. We therefore start solving this system with the second equation. Either we "see" the solution or we recognize it as a homogeneous differential equation,

\bee
y'(t) - \lambda y(t) = 0
\eee

with $p(t) = - \lambda$ and therefore $P(t) = -\lambda t + C$. The solution therefore becomes

\bee
y(t) = D e^{\lambda t}
\eee

Plugging this into the first equation, we obtain

\bee
x'(t) - \lambda x(t) = b D e^{\lambda t}
\eee

Using the variation of parameter method from above, we have

\bee
v'(t) = \frac{f(t)}{g(t)} = \frac{ b D e^{\lambda t} }{ D e^{\lambda t} } = G \rightarrow v(t) = G t + H
\eee

and finally arrive at the following solution

\bee
y(t) = (Gt + H) e^{\lambda t} + A e^{\lambda t} = (Mt + N) e^{ \lambda t}
\eee

So the behaviour of the system is governed by the single eigenvalue; but since there is only one eigenvalue, we have the $t$-termi n the soluton as well.

The $t$-term controls the behaviour of the solution for small values of $t$; if $t$ is sufficiently large, the exponential term dominates the linear $t$-term.

The corresponding jupyter notebook can be found \href{https://github.com/ClemensFMN/Notebooks/blob/main/ODE/Ex_5.2.11.ipynb}{here}.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "journal"
%%% End:
