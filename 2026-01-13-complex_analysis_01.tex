\DiaryEntry{Complex Analysis, 1}{2026-01-13}{Complex Analysis}

\subsubsection{Introduction}

Based on \cite{agarwal2011complanalysis}. We consider a complex number $z = x + jy$ and have $\Re z = x, \Im z = y$. The complex conjugate $\bar{z}$ is defined as $\bar{z} = x - jy$ and from this we obtain the following

\begin{equation*}
\Re z = \frac{z + \bar{z}}{2}, \Im z = \frac{z - \bar{z}}{2j}        
\end{equation*}


There is the triangle inequality

\begin{equation*}
|z_1 + z_2| \leq |z_1| + |z_2|    
\end{equation*}

When we apply the inequality to $z_2 - z_1$ and $z_1$, we get another interesting form

\begin{equation*}
|z_2| \leq |z_2 - z_1| + |z_1| \rightarrow |z_2| - |z_1| \leq |z_2 - z_1|    
\end{equation*}

We can use the triangle inequality in the following bound

\begin{align*}
    |z_1 + z_2|^2 &= (z_1 + z_2)(\bar{z_1} + \bar{z_2}) = z_1 \bar{z_1} + z_1 \bar{z_2} + z_2 \bar{z_1} + z_2 \bar{z_2} \\
    &= |z_1|^2 + (z_1 \bar{z_2} + \overline{z_1 \bar{z_2}} )+ |z_2|^2 \\
    &= |z_1|^2 + 2 \Re (z_1 \bar{z_2}) + |z_2|^2 \\
    &\leq |z_1|^2 + 2 |z_1 z_2| + |z_2|^2 = (|z_1| + |z_2|)^2
\end{align*}


We can use the polar form of a complex number $e^{j \theta} = cos \theta + j \sin \theta$ in the following

\begin{equation*}
    (\cos \theta + j \sin \theta)^n = \left( e^{j \theta} \right)^n = e^{j n \theta} = \cos n \theta+  j \sin n \theta
\end{equation*}

\paragraph{Examples.} When $|z| = 1$, we can bound

\begin{equation*}
|z^2 + 2z + 6 + 8j| \leq |z|^2 + 2 |z| + |6 + 8j| = 1 + 2 + \sqrt{36 + 64} = 13 \qed
\end{equation*}

We can use the polar form to obtain some trigonometric identities; eg

\begin{align*}
    \cos 3 \theta &= \Re \left( cos 3\theta+  j \sin 3 \theta\right) \\
&= \Re \left( cos \theta + j \sin \theta\right)^3 \\
&= \Re \left( cos^3 \theta + 3j \cos^2 \theta \sin \theta - 3 \cos \theta\sin^2 \theta - j \sin^3 \theta \right) \\
&= cos^3 \theta  - 3 \cos \theta\sin^2 \theta = cos^3 \theta  - 3 \cos \theta (1 - \cos^2 \theta) = 4 \cos^3 \theta - 3 \cos \theta
\end{align*}

We also have

\bee
(1 + j)^{24} = \left( \sqrt{2} e^{j \pi / 4} \right)^{24} = \sqrt{2}^{24} e^{j 24 \pi / 4} = 2^{12} e^{j 6 \pi} = 2^{12} \qed
\eee

\subsubsection{Complex Functions}

A complex function (complex-valued of a complex variable) $f$ defined on $\Sc$ is a rule that assigns to each $z = x+jy$ in $\Sc$ a unique complex number $w = u + iv$ and written as $f : \Sc \rightarrow \Sc$.

As every complex number $z$ is characterized by a pair of real numbers $x$ and $y$, a complex function $f$ of the complex variable $z$ can be specified by two real functions $u = u(x, y)$ and $v = v(x, y)$. It is customary to write $w = f (z) = u(x, y)+iv(x, y)$.


\paragraph{Exponential Function.} The exponential function is defined as below,

\bee
e^{z} = e^{x + jy} = e^x e^{jy} = e^x (\cos(y) + j \sin(y))
\eee

Splitting this into real and impaginary parts, we obtain

\bee
u(z) = u(x,y) = e^x \cos y, \quad v(z) = v(x,y) = e^x \sin y
\eee

We can use this to (re)derive some trigonometric identities. We have

\bee
e^{j (z_1 + z_2)} = \cos (z_1 + z_2) + j \sin (z_1 + z_2)
\eee

However, we can also expand the exponential and then split into real and imaginary parts,

\begin{align*}
e^{j (z_1 + z_2)} &= e^{j z_1} \cdot e^{j z_2} = (\cos z_1 + j \sin z_1) \cdot (\cos z_2 + j \sin z_2) \\
&= \cos z_1 \cos z_2 - \sin z_1 \sin z_2 + j \cos z_1 \sin z_2 + j \cos z_2 \sin z_1
\end{align*}

Comparing real and imaginary parts, we obtain

\begin{align*}
    \cos (z_1 + z_2) &= \cos z_1 \cos z_2 - \sin z_1 \sin z_2 \\
    \sin (z_1 + z_2) &= \cos z_1 \sin z_2 + \cos z_2 \sin z_1
\end{align*}


\paragraph{Trigonometric Functions.} We start with

\begin{align*}
    e^{j \theta} &= \cos \theta + j \sin \theta \\
    e^{-j \theta} &= \cos \theta - j \sin \theta
\end{align*}

Adding the two equations yields

\bee
\cos \theta = \frac{1}{2} \left( e^{j \theta} + e^{-j \theta} \right)
\eee

Subtracting yields

\bee
\sin \theta = \frac{1}{2j} \left( e^{j \theta} - e^{-j \theta} \right)
\eee

\subsubsection{Complex Differentiation}

The derivative of a complex function $f(z)$ is defined as

\bee
\frac{df(z)}{dz} = \lim_{\Delta z \rightarrow 0} \frac{f(z + \Delta z)}{\Delta z}
\eee

Note that this simple definition disguises the fact, that we can choose $\Delta z$ to have arbitrary direction and - in the general case - it is not clear that the limit is independent of the direction.

A complex function is called \emph{analytic} if the derivative is independent of the direction.

We next derive a condition, when a complex function is analytic.

We derive the complex derivative for two cases: (i) $\Delta z = \Delta x$ being real and (ii) $\Delta z = j \Delta y$ being imaginary. For each case, we calculate the derivative. In the following we split the real and imaginary parts; so we have

\bee
f(z) = u(x,y + j(v(x,y)))
\eee

\paragraph{Case (i): $\Delta z = \Delta x$.} We have

\begin{align*}
\frac{df(z)}{dz} &= \lim_{\Delta x \rightarrow 0} \frac{u(x + \Delta x, y) + j v(x + \Delta x, y) - u(x, y) - j v(x, y) }{\Delta x} \\
&= \lim_{\Delta x \rightarrow 0} \frac{u(x + \Delta x, y) - u(x, y) + j v(x + \Delta x, y)  - j v(x, y) }{\Delta x} = \frac{\partial u}{\partial x} + j \frac{\partial v}{\partial x}
\end{align*}


\paragraph{Case (ii): $\Delta z = j \Delta y$.} We have

\begin{align*}
\frac{df(z)}{dz} &= \lim_{\Delta y \rightarrow 0} \frac{u(x, y + \Delta y) + j v(x, y + \Delta y) - u(x, y) - j v(x, y) }{j \Delta y} \\
&= \lim_{\Delta y \rightarrow 0} \frac{v(x, y + \Delta y)  - v(x,y) - j v(u, y + \Delta y) + j u(x, y) }{\Delta y} = \frac{\partial v}{\partial y} - j \frac{\partial u}{\partial y}
\end{align*}

If we want the derivative to be independent of the direction, the real and imaginary part have to be the same; so we have the \emph{Cauchy-Riemann equations}

\be\label{2026-01-13:eq1}
\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}, \quad \frac{\partial u}{\partial y} = - \frac{\partial v}{\partial x}
\ee

\begin{theorem}
    A \emph{necessary} condition for a function $f (z) = u(x, y) + iv(x, y)$ to be differentiable at a point $z_0$ is that the Cauchy-Riemann equations hold at $z_0$. Consequently, if $f$ is analytic in an open set $\Sc$, then the Cauchy-Riemann equations must be satisfied at every point of $\Sc$.
\end{theorem}


\paragraph{Examples} The simplest example for a non-analytic function is $f(z) = \bar{z}$ with $u(x,y) = x, v(x,y) = -y$. Plugging this into \eqref{2026-01-13:eq1}, we obtain

\bee
    \frac{\partial u}{\partial x} = 1, \quad \frac{\partial u}{\partial y} = 0, \quad \frac{\partial v}{\partial x} = 0, \quad \frac{\partial v}{\partial y} = -1
\eee

The first Cauchy-Riemann equation, $\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}$, does \emph{not} hold, therefore the function is \emph{not} analytic.

We can also show this "manually", by using the derivative definition and taking the limits. We start with case (i) $\Delta z = \Delta x$ and obtain

\begin{align*}
\frac{df(z)}{dz} &= \lim_{\Delta x \rightarrow 0} \frac{(x + \Delta x) + j (-y) - x + j y }{\Delta x} \\
&= \lim_{\Delta x \rightarrow 0} \frac{\Delta x}{\Delta x} = 1
\end{align*}

Case (ii) is $\Delta z = j \Delta y$ and we have

\begin{align*}
\frac{df(z)}{dz} &= \lim_{\Delta y \rightarrow 0} \frac{ x + j(-y-\Delta y) -x + jy}{j \Delta y} \\
&= \lim_{\Delta y \rightarrow 0} \frac{- j\Delta y}{\Delta y} = -j \qed
\end{align*} \qed

In a similar spirit, the squared absolute value $f(z) = |z|^2$ is also not analytic. We have $u(x,y) = x^2 + y^2, v(x,y) = 0$ and therefore

\bee
    \frac{\partial u}{\partial x} = 2x, \quad \frac{\partial u}{\partial y} = 2y, \quad \frac{\partial v}{\partial x} = 0, \quad \frac{\partial v}{\partial y} = 0 \qed
\eee

We finally consider $f(z) = (x^2 + y) + j(y^2 - x)$; we have $u(x,y) = x^2 + y, v(x,y) = y^2 - x$ and we can use the Cauchy-Riemann equations to obtain

\bee
    \frac{\partial u}{\partial x} = 2x, \quad \frac{\partial u}{\partial y} = 1, \quad \frac{\partial v}{\partial x} = -1, \quad \frac{\partial v}{\partial y} = 2y
\eee

Comparing with \eqref{2026-01-13:eq1}, we see that the Cauchy-Riemann equations are only fulfilled on the line $x = y$; however a line is \emph{not} an open set; therefore the function is \emph{not} analytic. \qed

I suspect that all functions which explicitly use $x$ and $y$ separately, are often not analytic.

We have another theorem.

\begin{theorem}
    Sufficient Conditions for Differentiability: Let $f(z) = u(x, y) + jv(x, y)$ be defined in some open set $\Sc$ containing the point $z_0$. If the first order partial derivatives of $u$ and $v$ exist in $\Sc$, are continuous at $z_0$, and satisfy the Cauchy-Riemann equations at $z_0$, then $f$ is differentiable at $z_0$. Moreover,

    \bee
        f'(z_0) = \frac{\partial u}{\partial x} (x_0, y_0) + j \frac{\partial v}{\partial x} (x_0, y_0) = \frac{\partial v}{\partial y} (x_0, y_0) - j \frac{\partial v}{\partial x} (x_0, y_0)
    \eee
\end{theorem}

Consequently, if the first-order partial derivatives are continuous and satisfy the Cauchy-Riemann equations at all points of $\Sc$, then $f$ is analytic in $\Sc$. We also note that if $f$ is  differentiable only at finitely many points, then it is nowhere analytic.

Being analytic has a wide range of consequences; for example the following theorem.

\begin{theorem}
    If $f(z)$ is analytic in a domain $\Sc$ and if $f'(z) = 0$ everywhere in $\Sc$, then $f(z)$ is a constant in $\Sc$.
\end{theorem}

Proof: Since $f'(z) = 0$ in $\Sc$, all first-order partial derivatives of $u$ and $v$ vanish in $\Sc$; i.e., $\partial u / \partial x = \partial u / \partial y = \partial v / \partial x = \partial v / \partial y = 0$. Now, since S is connected, we have $u = $ a constant and $v = $ a constant in $\Sc$. Consequently, $f = u + jv$ is also a constant in $\Sc$. Note: The connectedness of $\Sc$ is essential for the proof (some technical detail).

A similar argument holds for functions with constant absolute value.

\begin{theorem}
    If $f$ is analytic in a domain $\Sc$ and if $|f|$ is constant there, then $f$ is constant.
\end{theorem}

Proof: With $f(z) = u(x,y) + j v(x,y)$ and $|f(z)| = 0$, then $u = v = 0$ and $f = 0$ (ie constant). If $|f|^2 = u^2 + v^2 = c \neq 0$, we take the partial derivatives of this expression with respect to $x$ and $y$, respectively, and have

\begin{align*}
& 2 u \frac{\partial u}{\partial x} + 2 v \frac{\partial v}{\partial x} = 0 \\
& 2 u \frac{\partial u}{\partial y} + 2 v \frac{\partial v}{\partial y} = 0 \\
\end{align*}

Using the Cauchy-Riemann equations (and dividing by two), we can rewrite this as

\begin{align*}
& u \frac{\partial u}{\partial x} - v \frac{\partial u}{\partial y} = 0 \\
& v \frac{\partial u}{\partial x} + u \frac{\partial u}{\partial y} = 0 \\
\end{align*}

Let's multiply the first equation by $u$ and the second by $v$ in order to arrive at

\begin{align*}
& u^2 \frac{\partial u}{\partial x} - u v \frac{\partial u}{\partial y} = 0 \\
& v^2 \frac{\partial u}{\partial x} + u v \frac{\partial u}{\partial y} = 0 \\
\end{align*}

Adding the two equations yields

\bee
( u^2 + v^2 ) \frac{\partial u}{\partial x}= 0
\eee

In a simialr spirit, we obtain

\bee
( u^2 + v^2 ) \frac{\partial u}{\partial y}= 0
\eee

We consider the case $|f|^2 = u^2 + v^2 = c \neq 0$, so the partial derivatives in both expressions have to be zero. The same holds for the partial derivatives of $v$ with respect to $x$ and $y$, respectively. All in all all four partial derivatives have to be zero and as consequence $f$ is a constant function. \qed

We can further develop the Cauchy-Riemann equations to gain more insight. We start with

\bee
\frac{\partial u}{\partial x} = \frac{\partial v}{\partial y}, \quad \frac{\partial u}{\partial y} = - \frac{\partial v}{\partial x}
\eee

Differentiating again with respect to $x$ yields

\bee
\frac{\partial^2 u}{\partial x^2} = \frac{\partial^2 v}{\partial x \partial y}, \quad \frac{\partial^2 u}{\partial x \partial y} = - \frac{\partial^2 v}{\partial x \partial y}
\eee

Differentiation with respect to $y$ yields

\bee
\frac{\partial^2 u}{\partial x \partial y} = \frac{\partial^2 v}{\partial^2 y}, \quad \frac{\partial^2 u}{\partial y^2} = - \frac{\partial^2 v}{\partial x \partial y}
\eee

Combining the two sets of equations, we obtain

\bee
\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} = 0, \quad \frac{\partial^2 v}{\partial x^2} + \frac{\partial^2 v}{\partial y^2} = 0
\eee

So we have converted the Cauchy-Riemann equations into two (independent) second-order partial differential equations. These equations are called the \emph{Laplacian equations}. They occur in the study of problems dealing with electric and magnetic fields, stationary states, hydrodynamics, diffusion, and so on.

A real-valued function $\phi(x, y)$ is said to be harmonic in a domain $\Sc$ if all its second-order partial derivatives are continuous in $\Sc$ and it satisfies $\partial^2 \phi / \partial x^2 + \partial^2 \phi / \partial y^2 = 0$ at each point of $\Sc$.

\begin{theorem}
    If $f(z) = u(x,y) + j v(x,y)$ is analytic in a domain $\Sc$, then each function $u(x,y)$ and $v(x,y)$ is harmonic on $\Sc$.
\end{theorem}


Let $u(x, y)$ and $v(x, y)$ be two functions harmonic in a domain $\Sc$ that satisfy the Cauchy-Riemann equations at every point of $\Sc$. Then, $u(x, y)$ and $v(x, y)$ are called harmonic conjugates of each other. Knowing one of them, we can reconstruct the other to within an arbitrary constant.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "journal"
%%% End: